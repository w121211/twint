{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app\n",
    "\n",
    "rss sources:\n",
    "https://tw.stock.yahoo.com/rss_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/twint/app\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/twint/app\n",
    "# !pip install -e .\n",
    "# !python -m pytest tests/test_scrapers.py::test_cnbc_page_tags -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/twint/app\n",
      "{'run': {'scraper': 'rss', 'n_workers': 1, 'loop_every': 3600}, 'store': {'es': {'host': 'es:9200'}, 'db': {'user': 'sqlpad', 'password': 'sqlpad', 'host': 'pg', 'dbname': 'test'}}, 'scraper': {'rss': {'entry': './resource/rss_news_us.csv', 'fetch_rss_every_n_seconds': 604800, 'force_fetch': False}, 'cnbc': {'store': 'es'}, 'cnyes_api': {'start': [2020, 5, 5], 'until': None}}, 'proxy': {'enabled': True, 'path': './proxies.txt'}}\n",
      "[2020-07-21 15:47:19,535][app.scrapers.base][INFO] - scraper start running: 1 workers, loop every 3600 seconds\n",
      "[2020-07-21 15:47:19,679][app.scrapers.rss][INFO] - start scraping: https://www.yahoo.com/news/rss\n",
      "[2020-07-21 15:48:38,451][app.scrapers.rss][INFO] - page downloaded: https://www.yahoo.com/news/rss\n",
      "[2020-07-21 15:48:40,054][app.scrapers.rss][INFO] - page parsed & saved: https://www.yahoo.com/news/rss\n",
      "[2020-07-21 15:48:45,067][app.scrapers.rss][INFO] - start scraping: https://www.cnbc.com/id/100003114/device/rss/rss.html\n",
      "[2020-07-21 15:48:46,713][app.scrapers.rss][INFO] - page downloaded: https://www.cnbc.com/id/100003114/device/rss/rss.html\n",
      "[2020-07-21 15:48:47,381][app.scrapers.rss][INFO] - page parsed & saved: https://www.cnbc.com/id/100003114/device/rss/rss.html\n",
      "[2020-07-21 15:48:52,395][app.scrapers.rss][INFO] - start scraping: https://www.investing.com/rss/news.rss\n",
      "[2020-07-21 15:48:54,152][app.scrapers.rss][INFO] - page downloaded: https://www.investing.com/rss/news.rss\n",
      "[2020-07-21 15:48:54,486][app.scrapers.rss][INFO] - page parsed & saved: https://www.investing.com/rss/news.rss\n",
      "[2020-07-21 15:48:59,497][app.scrapers.rss][INFO] - start scraping: http://rss.cnn.com/rss/edition.rss\t\n",
      "[2020-07-21 15:49:00,065][app.scrapers.rss][INFO] - page downloaded: http://rss.cnn.com/rss/edition.rss\t\n",
      "[2020-07-21 15:49:00,162][app.scrapers.rss][INFO] - scrape internal error & skiped: http://rss.cnn.com/rss/edition.rss\t\n",
      "[2020-07-21 15:49:00,163][app.scrapers.rss][ERROR] - 'published_parsed'\n",
      "[2020-07-21 15:49:00,180][app.scrapers.base][INFO] - all jobs done.\n",
      "[2020-07-21 15:49:00,182][app.scrapers.base][INFO] - all jobs done, scraper sleep for 3499.354214 seconds\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/twint/app\n",
    "# !python -m app.main run.scraper=cnbc run.n_workers=1\n",
    "# !python -m app.main run.scraper=rss run.n_workers=1 run.loop_every=86400 scraper.rss.entry=./resource/rss_yahoo_us_stock.csv\n",
    "# !python -m app.main run.scraper=rss run.n_workers=1 run.loop_every=43200 scraper.rss.entry=./resource/rss_yahoo_us_indicies.csv\n",
    "# !python -m app.main run.scraper=rss run.n_workers=1 run.loop_every=43200 scraper.rss.entry=./resource/rss_yahoo_tw.csv\n",
    "# !python -m app.main run.scraper=rss run.n_workers=1 run.loop_every=7200 scraper.rss.entry=./resource/rss_news_us.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twint\n",
    "\n",
    "twitter account: CNBC, CNNBusiness, businessinsider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fake-useragent in /usr/local/lib/python3.7/site-packages (0.1.11)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %cd /workspace/twint\n",
    "# !pip install e .\n",
    "# !twint -u CNBC\n",
    "# !pip install -U fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import twint\n",
    "\n",
    "c = twint.Config()\n",
    "c.Username = \"CNBC\"\n",
    "c.Elasticsearch = \"http://es:9200\"\n",
    "c.Until='2015-01-01 00:00:00'\n",
    "\n",
    "# c.Search = \"fruit\"\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# elasticsearch\n",
    "\n",
    "query twint\n",
    "```json\n",
    "{\n",
    "  \"_source\": [\n",
    "    \"date\",\n",
    "    \"username\"\n",
    "  ],\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"username\": \"business\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"date\": {\n",
    "              \"gt\": \"2004-01-01 00:00:00\",\n",
    "              \"lt\": \"2023-01-01 00:00:00\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"from\": 0,\n",
    "  \"size\": 1000,\n",
    "  \"sort\": [\n",
    "    {\n",
    "      \"date\": \"asc\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "query cnyes\n",
    "http://localhost:9200/news_page/_search\n",
    "```json\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"wildcard\": {\n",
    "            \"from_url\": \"*cnyes.com*\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"range\": {\n",
    "            \"entry_published_at\": {\n",
    "              \"gte\": \"2020-05-01T00:00:00\",\n",
    "              \"lt\": \"2021-01-01T00:00:00\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"from\": 0,\n",
    "  \"size\": 1000,\n",
    "  \"sort\": [\n",
    "    {\n",
    "      \"entry_published_at\": \"desc\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"wildcard\": {\n",
    "            \"resolved_url\": \"*cnbc*\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"from\": 0,\n",
    "  \"size\": 1000,\n",
    "  \"sort\": [\n",
    "    {\n",
    "      \"entry_published_at\": \"desc\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch Dump\n",
    "\n",
    "https://github.com/taskrabbit/elasticsearch-dump  \n",
    "\n",
    "```\n",
    "npm install elasticdump -g\n",
    "```\n",
    "\n",
    "dump \n",
    "\n",
    "```\n",
    "multielasticdump \\\n",
    "  --direction=dump \\\n",
    "  --match='^.*$' \\\n",
    "  --input=http://es:9200 \\\n",
    "  --output=./dump \\\n",
    "  --fsCompress\n",
    "\n",
    "multielasticdump \\\n",
    "  --direction=load \\\n",
    "  --match='^.*$' \\\n",
    "  --input=./dump \\\n",
    "  --output=http://es:9200 \\\n",
    "  --fsCompress\n",
    "\n",
    "\n",
    "elasticdump \\\n",
    "  --input=http://es:9200/twinttweets \\\n",
    "  --output=./twinttweets_mapping_20200503.json \\\n",
    "  --type=mapping\n",
    "elasticdump \\\n",
    "  --input=http://es:9200/twinttweets \\\n",
    "  --output=./twinttweets_index_20200503.json \\\n",
    "  --type=data\n",
    "\n",
    "elasticdump \\\n",
    "  --input=http://es:9200/twinttweets \\\n",
    "  --output=$ \\\n",
    "  | gzip > ./twinttweets_index_20200504.json.gz\n",
    "  \n",
    "elasticdump \\\n",
    "  --input=http://es:9200/news_page \\\n",
    "  --output=$ \\\n",
    "  | gzip > ./news_page_index_20200615.json.gz\n",
    "```\n",
    "\n",
    "import\n",
    "\n",
    "```\n",
    "elasticdump \\\n",
    "  --input=./twinttweets_index_20200602.json.gz \\\n",
    "  --output=http://es:9200/twinttweets \\\n",
    "  --fsCompress\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock\n",
    "\n",
    "https://twstock.readthedocs.io/zh_TW/latest/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twstock\n",
      "  Downloading twstock-1.3.1-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 853 kB/s eta 0:00:01     |█████████████████████▋          | 1.3 MB 853 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from twstock) (2.23.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->twstock) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->twstock) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->twstock) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->twstock) (2020.4.5.1)\n",
      "Installing collected packages: twstock\n",
      "Successfully installed twstock-1.3.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install twstock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/twint/app\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/twint/app\n",
    "\n",
    "from app import tools\n",
    "\n",
    "tools.generate_rss_yahoo_csv(\n",
    "    save_to=\"./resource/rss_yahoo_us_indicies.csv\",\n",
    "        symbol_path=\"./resource/symbol_indicies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
