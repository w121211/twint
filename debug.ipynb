{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參考\n",
    "\n",
    "aiohttp scraper: https://github.com/gaojiuli/gain  \n",
    "tweet熱度：https://github.com/shirosaidev/stocksight  \n",
    "reuters scraper: https://github.com/wenyenwei/tensorflow-stock-news  \n",
    "https://stocknewsapi.com/  \n",
    "https://stackoverflow.com/questions/51537063/url-format-for-google-news-rss-feed  \n",
    "https://github.com/niderhoff/nlp-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/LIAAD/yake\n",
    "# !pip install nest_asyncio newspaper3k feedparser psycopg2\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twstock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install twstock\n",
    "import twstock\n",
    "twstock.__update_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='www.twse.com.tw', port=80): Max retries exceeded with url: /exchangeReport/STOCK_DAY?date=20200401&stockNo=2330 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8efe4989d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f8efe4989d0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    724\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 725\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='www.twse.com.tw', port=80): Max retries exceeded with url: /exchangeReport/STOCK_DAY?date=20200401&stockNo=2330 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8efe4989d0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c2c3de7be52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# twstock.codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwstock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2330'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# stock.fetch_from(2010, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/twstock/stock.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sid, initial_fetch)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Init data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_fetch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_31\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_month_year_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_month\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_year\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_month\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/twstock/stock.py\u001b[0m in \u001b[0;36mfetch_31\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/twstock/stock.py\u001b[0m in \u001b[0;36mfetch_from\u001b[0;34m(self, year, month)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_month_year_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/twstock/stock.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, year, month, sid, retry)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mretry_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             r = requests.get(self.REPORT_URL, params=params,\n\u001b[0;32m---> 59\u001b[0;31m                              proxies=get_proxies())\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='www.twse.com.tw', port=80): Max retries exceeded with url: /exchangeReport/STOCK_DAY?date=20200401&stockNo=2330 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8efe4989d0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# twstock.codes\n",
    "stock = twstock.Stock('2330')\n",
    "# stock.fetch_from(2010, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/twint/app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['173.234.232.49:3128',\n",
       " '206.214.82.80:3128',\n",
       " '173.234.248.66:3128',\n",
       " '206.214.82.218:3128',\n",
       " '206.214.82.5:3128',\n",
       " '173.234.232.170:3128',\n",
       " '192.161.163.220:3128',\n",
       " '173.234.248.57:3128',\n",
       " '192.161.163.206:3128',\n",
       " '206.214.82.173:3128']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /workspace/twint/app\n",
    "import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame(stock.data)\n",
    "# df.to_csv(\"tw-2330.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv('./proxies.txt', sep=\" \", header=None)\n",
    "list(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "\n",
    "cnbc = newspaper.build('https://www.cnbc.com/markets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in cnbc.articles:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /usr/local/lib/python3.7/site-packages/jieba/dict.txt ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.7376432418823242 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'al': {'android': {'app_name': 'Yahoo奇摩',\n",
       "               'package': 'com.yahoo.mobile.client.android.superapp',\n",
       "               'url': 'ysuper://story/%E5%8F%B0%E5%8C%97%E8%82%A1%E5%B8%82-%E6%95%A3%E6%88%B6%E8%B3%87%E9%87%91%E5%9B%9E%E7%B1%A0-%E6%8D%A7%E7%B4%85%E9%8A%85%E6%9D%BF%E8%82%A1-083011251/ab7c6727-940d-3d42-bd46-c8c887fc9083'},\n",
       "              'ios': {'app_name': 'Yahoo奇摩',\n",
       "               'app_store_id': 1437216700,\n",
       "               'url': 'ysuper://story/%E5%8F%B0%E5%8C%97%E8%82%A1%E5%B8%82-%E6%95%A3%E6%88%B6%E8%B3%87%E9%87%91%E5%9B%9E%E7%B1%A0-%E6%8D%A7%E7%B4%85%E9%8A%85%E6%9D%BF%E8%82%A1-083011251/ab7c6727-940d-3d42-bd46-c8c887fc9083'}},\n",
       "             'og': {'type': 'article',\n",
       "              'description': '【時報-台北電】台股投資人信心回升、資金回籠，集中市場融資餘額近期回升至1,100億元以上，朝1,200億元邁進中，並已完全回補3月19日融資大砍118億元的恐慌性拋售潮，低價銅板股仍是散戶進場首選。 \\u3000台股本波上演破底翻，指數從8,523點低點攻抵萬一與年線關卡，僅花了不到50個交易日，急殺急漲氣氛讓投資人情緒大洗三溫暖。 \\u3000近期隨著台股一路收復月、季線、萬點，再四度挑戰年線，集中市場的融資餘額已經回升至1,150億元左右，以3月19日投資人最恐慌當日、融資大砍118億元為分界點，這段期間以來，融資餘額已回補了226億元。 ...',\n",
       "              'site_name': 'Yahoo奇摩股市',\n",
       "              'title': '《台北股市》散戶資金回籠 捧紅銅板股 - Yahoo奇摩股市',\n",
       "              'url': 'https://tw.stock.yahoo.com/news/%E5%8F%B0%E5%8C%97%E8%82%A1%E5%B8%82-%E6%95%A3%E6%88%B6%E8%B3%87%E9%87%91%E5%9B%9E%E7%B1%A0-%E6%8D%A7%E7%B4%85%E9%8A%85%E6%9D%BF%E8%82%A1-083011251.html'},\n",
       "             'fb': {'app_id': 399384933466174, 'pages': 114062348679049},\n",
       "             'apple-itunes-app': 'app-id=1437216700,app-argument=ysuper://story/%E5%8F%B0%E5%8C%97%E8%82%A1%E5%B8%82-%E6%95%A3%E6%88%B6%E8%B3%87%E9%87%91%E5%9B%9E%E7%B1%A0-%E6%8D%A7%E7%B4%85%E9%8A%85%E6%9D%BF%E8%82%A1-083011251/ab7c6727-940d-3d42-bd46-c8c887fc9083',\n",
       "             'twitter': {'dnt': 'on',\n",
       "              'card': 'summary',\n",
       "              'site': '@Yahoo',\n",
       "              'description': '【時報-台北電】台股投資人信心回升、資金回籠，集中市場融資餘額近期回升至1,100億元以上，朝1,200億元邁進中，並已完全回補3月19日融資大砍118億元的恐慌性拋售潮，低價銅板股仍是散戶進場首選。 \\u3000台股本波上演破底翻，指數從8,523點低點攻抵萬一與年線關卡，僅花了不到50個交易日，急殺急漲氣氛讓投資人情緒大洗三溫暖。 \\u3000近期隨著台股一路收復月、季線、萬點，再四度挑戰年線，集中市場的融資餘額已經回升至1,150億元左右，以3月19日投資人最恐慌當日、融資大砍118億元為分界點，這段期間以來，融資餘額已回補了226億元。 ...',\n",
       "              'title': '《台北股市》散戶資金回籠 捧紅銅板股 - Yahoo奇摩股市'},\n",
       "             'referrer': 'origin',\n",
       "             'oath': {'guce': {'consent-host': 'guce.yahoo.com'}},\n",
       "             'description': '【時報-台北電】台股投資人信心回升、資金回籠，集中市場融資餘額近期回升至1,100億元以上，朝1,200億元邁進中，並已完全回補3月19日融資大砍118億元的恐慌性拋售潮，低價銅板股仍是散戶進場首選。 \\u3000台股本波上演破底翻，指數從8,523點低點攻抵萬一與年線關卡，僅花了不到50個交易日，急殺急漲氣氛讓投資人情緒大洗三溫暖。 \\u3000近期隨著台股一路收復月、季線、萬點，再四度挑戰年線，集中市場的融資餘額已經回升至1,150億元左右，以3月19日投資人最恐慌當日、融資大砍118億元為分界點，這段期間以來，融資餘額已回補了226億元。 ...'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "# url = \"https://www.cnbc.com/2020/04/20/oil-markets-us-crude-futures-in-focus-as-coronavirus-dents-demand.html\"\n",
    "# url = \"https://news.cnyes.com/news/id/4474677\"\n",
    "url = \"https://tw.stock.yahoo.com/news/%E5%8F%B0%E5%8C%97%E8%82%A1%E5%B8%82-%E6%95%A3%E6%88%B6%E8%B3%87%E9%87%91%E5%9B%9E%E7%B1%A0-%E6%8D%A7%E7%B4%85%E9%8A%85%E6%9D%BF%E8%82%A1-083011251.html\"\n",
    "a = newspaper.Article(url=url)\n",
    "a.download()\n",
    "a.parse()\n",
    "a.meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<a href=\"https://invest.cnyes.com/twstock/tws/2301\">2301-TW</a>) &#20170; (9) &#26085;&#20659;&#20986;&#26071;&#19979;&#24037;&#26989;&#33258;&#21205;&#21270;&#20107;&#26989;&#37096;&#35009;&#21729;&#30334;&#20154;&#65292;&#23565;&#27492;&#65292;&#20809;&#23542;&#31185;&#28548;&#28165;&#65292;&#21482;&#26159;&#22240;&#25033;&#32771;&#26680;&#65292;&#36914;&#34892;&#30340;&#32068;&#32340;&#20839;&#37096;&#24120;&#24907;&#24615;&#35519;&#25972;&#65292;&#20197;&#20839;&#36681;&#28858;&#20778;&#20808;&#65292;&#20006;&#38750;&#22914;&#22806;&#20659;&#25152;&#35498;&#30340;&#35009;&#21729;&#19978;&#30334;&#20154;&#12290;'\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "for e in a.clean_top_node.cssselect('a'):\n",
    "    print(etree.tostring(e))\n",
    "\n",
    "# for p in set([e.getparent() for e in node.cssselect('a')]):\n",
    "#     text = etree.tostring(\n",
    "#         p, method='text', encoding='utf-8').decode('utf-8').strip()\n",
    "#     tk = _Ticker(text)\n",
    "\n",
    "#     for a in p.cssselect('a'):\n",
    "#         href = a.get('href')\n",
    "#         queries = dict(urllib.parse.parse_qsl(\n",
    "#             urllib.parse.urlsplit(href).query))\n",
    "#         try:\n",
    "#             tk.labels.append((a.text, queries['symbol']))\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#     if len(tk.labels) > 0:\n",
    "#         tickers.append(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N2.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N3.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N4.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N5.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N6.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N7.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N8.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N9.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N10.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N11.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N12.html\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "True\n",
      "nan https://tw.stock.yahoo.com/rss/url/d/e/N13.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/workspace/twint/app/resource/rss_yahoo_tw.csv')\n",
    "# return df.iterrows()\n",
    "for index, r in df.iterrows():\n",
    "    print(type(r['url']))    \n",
    "    print(type(r['ticker']))    \n",
    "    print(np.isnan(r['ticker']))\n",
    "    print(r['ticker'], r['url'])\n",
    "    \n",
    "# pd.DataFrame({\n",
    "#     \"url\": [1,2,3,4]\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "from newspaper import Article\n",
    "\n",
    "url = 'http://cnb.cx/sytyjc'\n",
    "# url = 'https://www.cnbc.com/2020/04/19/why-big-techs-coronavirus-goodwill-wont-help-in-antitrust-probes.html'\n",
    "\n",
    "async def get():\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        async with sess.get(url) as resp:\n",
    "#             print(resp)\n",
    "#             print(resp.status)\n",
    "#             print(resp.headers)\n",
    "#             print(resp.url)\n",
    "#             print(resp.history)\n",
    "            html = await resp.text()\n",
    "#             article = Article(str(resp.url))\n",
    "#             article.set_html()\n",
    "#             article.parse()\n",
    "            return resp, html\n",
    "\n",
    "# article, resp = await get()\n",
    "# print(article)\n",
    "try:\n",
    "    resp, html = await get()\n",
    "except aiohttp.ClientError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'error' is not defined\n",
      "aa\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    try:\n",
    "        raise error()\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    print('aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "p = re.compile(r'^\\/tag\\/(\\w+)') \n",
    "m = p.search('/tag/') \n",
    "# print(m.group())\n",
    "print(m)\n",
    "# m.group(1)\n",
    "if m is not None:\n",
    "    print(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tag/光寶科\n",
      "/tag/LED\n",
      "/tag/資訊\n",
      "/tag/電源\n",
      "/tag/裁員\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href is not None and '/tag/' in href:\n",
    "        print(href)\n",
    "#     print(link.get('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# url = \"https://www.cnbc.com/id/45044666\" # 404\n",
    "urls = [\n",
    "    \"https://httpstat.us/404\",\n",
    "    \"https://httpstat.us/200\",\n",
    "]\n",
    "\n",
    "async def get(url):\n",
    "    ua = UserAgent(verify_ssl=False, use_cache_server=False).random\n",
    "    async with aiohttp.ClientSession(raise_for_status=True, headers=[(\"User-Agent\", ua)]) as sess:\n",
    "            async with sess.get(url) as resp:\n",
    "                return resp\n",
    "\n",
    "\n",
    "# await asyncio.gather(*[get(u) for u in urls])\n",
    "\n",
    "\n",
    "    \n",
    "try:\n",
    "    resp = await get(urls[1])\n",
    "    print(resp.status)\n",
    "    print(type(resp.status))\n",
    "except aiohttp.ClientResponseError as e:\n",
    "    print(e)\n",
    "    print(type(e.status))\n",
    "    print(e.headers)\n",
    "    print(e.request_info.real_url)\n",
    "    print(e.request_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# article.meta_keywords\n",
    "# article.meta_site_name\n",
    "# s = json.dumps(article.meta_data)\n",
    "# json.loads(s)\n",
    "# article.article_html\n",
    "# article.source_url\n",
    "type(article.meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element div at 0x7f81a24329b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "article.clean_top_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedTicker(text=\"Recent actions by both agencies back up their claims. At the end of March, the DOJ Antitrust Division announced it would require military technology companies Raytheon and United Technologies Corporation to divest parts of their businesses to proceed with their proposed merger. On April 1, the FTC announced its lawsuit to unwind tobacco company Altria's $12.8 billion investment in Juul, the e-cigarette company accused of luring adolescents to its products with its marketing.\", tickers=[_TickerAnchor(text='Raytheon ', ticker='UTX'), _TickerAnchor(text='Altria', ticker='MO')])\n",
      "ParsedTicker(text='Up until recently, Facebook, Google, Amazon and Apple had been met with unyielding scrutiny in Washington and most state attorneys general offices, barraged by questions of dominance and privacy violations. Facebook and Google have been most visibly pursued by federal authorities and state attorneys.', tickers=[_TickerAnchor(text='Facebook', ticker='FB'), _TickerAnchor(text='Google', ticker='GOOGL'), _TickerAnchor(text='Amazon', ticker='AMZN'), _TickerAnchor(text='Apple', ticker='AAPL'), _TickerAnchor(text='Google', ticker='GOOGL')])\n",
      "ParsedTicker(text=\"Still, with tech companies ingraining themselves in the federal government's recovery plans, government watchdogs fear White House pressure could taint the probes. Antitrust professionals have frequently pointed to a handful of cases undertaken by the Trump administration's Antitrust Division, like its attempt to block AT&T's acquisition of Time Warner, that they argue were influenced by the White House. The Antitrust Division has repeatedly denied outside influence.\", tickers=[_TickerAnchor(text='AT&T', ticker='T')])\n"
     ]
    }
   ],
   "source": [
    "from urllib import parse\n",
    "import urllib\n",
    "from lxml import etree\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# resp\n",
    "# resp.headers\n",
    "article.meta_data\n",
    "# type(article.top_node)\n",
    "# tostring(article.top_node)\n",
    "\n",
    "# soup = BeautifulSoup(article.top_node, 'lxml')\n",
    "# BeautifulSoup(doc, 'lxml')\n",
    "# soup\n",
    "\n",
    "# type(article.top_node)\n",
    "# print(etree.tostring(article.top_node, pretty_print=True).decode('utf-8'))\n",
    "# print(etree.tostring(article.clean_top_node, pretty_print=True).decode('utf-8'))\n",
    "# print('this is a \\'try')\n",
    "\n",
    "# for e in article.clean_top_node.cssselect('a'):\n",
    "#     print(etree.tostring(e))\n",
    "#     print(e.getparent().text)\n",
    "#     print(e.text)\n",
    "#     print(e.get('href'))\n",
    "#     print(e.keys())\n",
    "\n",
    "# es = article.clean_top_node.cssselect('a')\n",
    "# href = e.get('href')\n",
    "# print(dict(urllib.parse.parse_qsl(urllib.parse.urlsplit(href).query)))\n",
    "# print(e.text)\n",
    "# print(etree.tostring(e.getparent(), method='text', pretty_print=True, encoding='utf-8').decode('utf-8'))\n",
    "# print(e.getparent().text)\n",
    "# print(etree.tostring(article.clean_top_node, pretty_print=True).decode('utf-8'))\n",
    "\n",
    "# es[0].getparent() is es[1].getparent()\n",
    "# set([es[0].getparent(), es[1].getparent()])\n",
    "# e = es[0].getparent()\n",
    "# # e.cssselect('a')\n",
    "# print(etree.tostring(e, method='text', encoding='utf-8').decode('utf-8').strip())\n",
    "# for a in e.cssselect('a'):\n",
    "#     print(etree.tostring(a, with_tail=False))\n",
    "#     print(a.text)\n",
    "#     print(a.items())\n",
    "\n",
    "import dataclasses\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class _TickerAnchor:\n",
    "    text: str\n",
    "    ticker: str\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ParsedTicker:\n",
    "    '''<p>...some text...<a href='$AAA'>...some anchor text</a>...<a>....</a>...</p>\n",
    "    '''\n",
    "    text: str\n",
    "    tickers: List[_TickerAnchor] = dataclasses.field(default_factory=list)\n",
    "\n",
    "\n",
    "node =  article.clean_top_node\n",
    "\n",
    "data = []\n",
    "for p in set([e.getparent() for e in node.cssselect('a')]):\n",
    "    text = etree.tostring(\n",
    "        p, method='text', encoding='utf-8').decode('utf-8').strip()\n",
    "    parsed = ParsedTicker(text)\n",
    "#     print(parsed)\n",
    "    for a in p.cssselect('a'):\n",
    "#         etree.tostring(a)\n",
    "        href = a.get('href')\n",
    "        queries = dict(urllib.parse.parse_qsl(\n",
    "            urllib.parse.urlsplit(href).query))\n",
    "        try:\n",
    "            parsed.tickers.append(\n",
    "                _TickerAnchor(a.text, queries['symbol'])\n",
    "            )\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(parsed.tickers) > 0:\n",
    "        data.append(parsed)\n",
    "        print(parsed)\n",
    "\n",
    "# data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitResult(scheme='', netloc='', path='/quotes/', query='symbol=FB', fragment='')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'symbol': 'FB'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import parse\n",
    "import urllib\n",
    "url = \"/quotes/?symbol=FB\"\n",
    "# url = \"http://www.example.org/default.html?ct=32&op=92&item=98\"\n",
    "print(urllib.parse.urlsplit(url))\n",
    "# parse.parse_qs(parse.urlsplit(url).query)\n",
    "dict(urllib.parse.parse_qsl(urllib.parse.urlsplit(url).query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.18 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.45 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.61 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.29 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.23 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.78 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.46 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.36 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.67 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.71 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.36 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.26 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.96 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.98 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.48 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.26 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.73 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-1 has slept for 0.24 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-2 has slept for 0.83 seconds\n",
      "name 'aaa' is not defined\n",
      "worker-0 has slept for 0.94 seconds\n",
      "====\n",
      "3 workers slept in parallel for 3.99 seconds\n",
      "total expected sleep time: 10.77 seconds\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "async def worker(name, queue):\n",
    "    while True:\n",
    "        sleep_for = await queue.get()\n",
    "        try:\n",
    "            try:\n",
    "                await asyncio.sleep(sleep_for)\n",
    "                print(aaa)\n",
    "            except IOError:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            queue.task_done()\n",
    "            print(f'{name} has slept for {sleep_for:.2f} seconds')\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Create a queue that we will use to store our \"workload\".\n",
    "    queue = asyncio.Queue()\n",
    "\n",
    "    # Generate random timings and put them into the queue.\n",
    "    total_sleep_time = 0\n",
    "    for _ in range(20):\n",
    "        sleep_for = random.uniform(0.05, 1.0)\n",
    "        total_sleep_time += sleep_for\n",
    "        queue.put_nowait(sleep_for)\n",
    "\n",
    "    # Create three worker tasks to process the queue concurrently.\n",
    "    tasks = []\n",
    "    for i in range(3):\n",
    "        task = asyncio.create_task(worker(f'worker-{i}', queue))\n",
    "        tasks.append(task)\n",
    "\n",
    "    # Wait until the queue is fully processed.\n",
    "    started_at = time.monotonic()\n",
    "    await queue.join()\n",
    "    total_slept_for = time.monotonic() - started_at\n",
    "\n",
    "    # Cancel our worker tasks.\n",
    "    for task in tasks:\n",
    "        task.cancel()\n",
    "    # Wait until all worker tasks are cancelled.\n",
    "    await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    print('====')\n",
    "    print(f'3 workers slept in parallel for {total_slept_for:.2f} seconds')\n",
    "    print(f'total expected sleep time: {total_sleep_time:.2f} seconds')\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "ua.update()\n",
    "\n",
    "ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ua.random\n",
    "ua.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feedparser, rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "proxies = {\"http\": \"http://173.234.248.57:3128\", \"https\": \"http://173.234.248.57:3128\"}\n",
    "# proxies = {\"http\": \"http://192.161.163.206:3128\", \"https\": \"http://192.161.163.206:3128\"}\n",
    "r = requests.get('http://finance.yahoo.com/', proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Referrer-Policy': 'no-referrer-when-downgrade', 'Strict-Transport-Security': 'max-age=15552000', 'X-Frame-Options': 'SAMEORIGIN', 'Content-Security-Policy': 'sandbox allow-downloads allow-forms allow-modals allow-same-origin allow-scripts allow-popups allow-popups-to-escape-sandbox allow-top-navigation-by-user-activation allow-presentation;', 'Content-Type': 'text/html; charset=utf-8', 'Content-Encoding': 'gzip', 'Set-Cookie': 'B=29hqlftfeklo9&b=3&s=l5; expires=Wed, 17-Jun-2021 17:46:49 GMT; path=/; domain=.yahoo.com', 'Date': 'Wed, 17 Jun 2020 17:46:49 GMT', 'Server': 'ATS', 'Cache-Control': 'max-age=0, private', 'Expires': '-1', 'Age': '0', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Expect-CT': 'max-age=31536000, report-uri=\"http://csp.yahoo.com/beacon/csp?src=yahoocom-expect-ct-report-only\"', 'X-XSS-Protection': '1; mode=block', 'X-Content-Type-Options': 'nosniff'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code\n",
    "# r.text\n",
    "r.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install aiohttp_proxy\n",
    "# import aiohttp\n",
    "# from aiohttp_proxy import ProxyConnector, ProxyType\n",
    "\n",
    "# async def fetch():\n",
    "#     connector = ProxyConnector.from_url('http://173.234.248.57:3128')\n",
    "#     ### or use ProxyConnector constructor\n",
    "# #     connector = ProxyConnector(\n",
    "# #         proxy_type=ProxyType.SOCKS5,\n",
    "# #         host='173.234.232.170',\n",
    "# #         port=3128,\n",
    "# # #         username='user',\n",
    "# # #         password='password',\n",
    "# #         rdns=True\n",
    "# #     )\n",
    "#     async with aiohttp.ClientSession(connector=connector) as session:\n",
    "#         async with session.get(\"https://finance.yahoo.com\") as resp:\n",
    "#             print(resp.status)\n",
    "#             return await response.text()\n",
    "\n",
    "# await fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientHttpProxyError",
     "evalue": "403, message='Forbidden', url=URL('http://173.234.248.57:3128')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientHttpProxyError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df9160a14375>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-df9160a14375>\u001b[0m in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__aenter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_RetType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx)\u001b[0m\n\u001b[1;32m    481\u001b[0m                                 \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                                 \u001b[0mtraces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m                             )\n\u001b[1;32m    485\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                 \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                     \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             _, proto = await self._create_proxy_connection(\n\u001b[0;32m--> 856\u001b[0;31m                 req, traces, timeout)\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             _, proto = await self._create_direct_connection(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/aiohttp/connector.py\u001b[0m in \u001b[0;36m_create_proxy_connection\u001b[0;34m(self, req, traces, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m                             \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m                             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                             headers=resp.headers)\n\u001b[0m\u001b[1;32m   1084\u001b[0m                     \u001b[0mrawsock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'socket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mrawsock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientHttpProxyError\u001b[0m: 403, message='Forbidden', url=URL('http://173.234.248.57:3128')"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import feedparser\n",
    "\n",
    "headers = {\n",
    "#     \"If-None-Match\": \"246ce00049b1df9930d4dc344180574f\"\n",
    "}\n",
    "\n",
    "async def get():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "#         async with session.get('http://finance.yahoo.com/rss/industry?s=yhoo', headers=headers) as resp:\n",
    "        async with session.get('https://finance.yahoo.com/',\n",
    "                               proxy=\"http://173.234.248.57:3128\",\n",
    "                               headers=headers) as resp:\n",
    "            print(resp.status)\n",
    "            print(resp.headers)\n",
    "            t = await resp.text()\n",
    "            return feedparser.parse(t)\n",
    "\n",
    "await get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "f = feedparser.parse('https://tw.stock.yahoo.com/rss/url/d/e/N2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '《各報要聞》川普出招制裁陸！撤銷香港特殊待遇 宣布退出世衛',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': 'https://tw.stock.yahoo.com/rss/url/d/e/N2.html',\n",
       "  'value': '《各報要聞》川普出招制裁陸！撤銷香港特殊待遇 宣布退出世衛'},\n",
       " 'links': [{'rel': 'alternate',\n",
       "   'type': 'text/html',\n",
       "   'href': 'https://tw.stock.yahoo.com/news/各報要聞-川普出招制裁陸-撤銷香港特殊待遇-宣布退出世衛-005758046.html'}],\n",
       " 'link': 'https://tw.stock.yahoo.com/news/各報要聞-川普出招制裁陸-撤銷香港特殊待遇-宣布退出世衛-005758046.html',\n",
       " 'published': 'Sun, 31 May 2020 08:57:58 CST',\n",
       " 'published_parsed': time.struct_time(tm_year=2020, tm_mon=5, tm_mday=31, tm_hour=14, tm_min=57, tm_sec=58, tm_wday=6, tm_yday=152, tm_isdst=0),\n",
       " 'id': '',\n",
       " 'guidislink': False,\n",
       " 'summary': '【時報-台北電】大陸全國人大28日通過港版「國安法」後，美國總統川普當地時間29日下午召開記者會，他指責大陸破壞對香港及世界承諾，而作為懲罰陸方措施的一環，美國將撤銷給予香港的特殊待遇，包括單獨關稅區...',\n",
       " 'summary_detail': {'type': 'text/html',\n",
       "  'language': None,\n",
       "  'base': 'https://tw.stock.yahoo.com/rss/url/d/e/N2.html',\n",
       "  'value': '【時報-台北電】大陸全國人大28日通過港版「國安法」後，美國總統川普當地時間29日下午召開記者會，他指責大陸破壞對香港及世界承諾，而作為懲罰陸方措施的一環，美國將撤銷給予香港的特殊待遇，包括單獨關稅區...'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "# import pprint\n",
    "\n",
    "# # pprint.pprint(f['entries'][0])\n",
    "# # j = json.dumps(f['entries'][0])\n",
    "# entries = json.loads(a)\n",
    "# len(entries)\n",
    "# entries[0]\n",
    "\n",
    "# f['entries'][0]\n",
    "# f\n",
    "f[\"entries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588509731.906466\n",
      "['https://news.cnyes.com/api/v3/news/category/headline?startAt=1262304000&endAt=1264896000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1264896000&endAt=1267488000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1267488000&endAt=1270080000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1270080000&endAt=1272672000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1272672000&endAt=1275264000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1275264000&endAt=1277856000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1277856000&endAt=1280448000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1280448000&endAt=1283040000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1283040000&endAt=1285632000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1285632000&endAt=1288224000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1288224000&endAt=1290816000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1290816000&endAt=1293408000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1293408000&endAt=1296000000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1296000000&endAt=1298592000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1298592000&endAt=1301184000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1301184000&endAt=1303776000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1303776000&endAt=1306368000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1306368000&endAt=1308960000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1308960000&endAt=1311552000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1311552000&endAt=1314144000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1314144000&endAt=1316736000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1316736000&endAt=1319328000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1319328000&endAt=1321920000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1321920000&endAt=1324512000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1324512000&endAt=1327104000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1327104000&endAt=1329696000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1329696000&endAt=1332288000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1332288000&endAt=1334880000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1334880000&endAt=1337472000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1337472000&endAt=1340064000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1340064000&endAt=1342656000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1342656000&endAt=1345248000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1345248000&endAt=1347840000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1347840000&endAt=1350432000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1350432000&endAt=1353024000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1353024000&endAt=1355616000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1355616000&endAt=1358208000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1358208000&endAt=1360800000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1360800000&endAt=1363392000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1363392000&endAt=1365984000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1365984000&endAt=1368576000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1368576000&endAt=1371168000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1371168000&endAt=1373760000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1373760000&endAt=1376352000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1376352000&endAt=1378944000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1378944000&endAt=1381536000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1381536000&endAt=1384128000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1384128000&endAt=1386720000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1386720000&endAt=1389312000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1389312000&endAt=1391904000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1391904000&endAt=1394496000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1394496000&endAt=1397088000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1397088000&endAt=1399680000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1399680000&endAt=1402272000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1402272000&endAt=1404864000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1404864000&endAt=1407456000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1407456000&endAt=1410048000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1410048000&endAt=1412640000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1412640000&endAt=1415232000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1415232000&endAt=1417824000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1417824000&endAt=1420416000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1420416000&endAt=1423008000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1423008000&endAt=1425600000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1425600000&endAt=1428192000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1428192000&endAt=1430784000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1430784000&endAt=1433376000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1433376000&endAt=1435968000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1435968000&endAt=1438560000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1438560000&endAt=1441152000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1441152000&endAt=1443744000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1443744000&endAt=1446336000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1446336000&endAt=1448928000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1448928000&endAt=1451520000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1451520000&endAt=1454112000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1454112000&endAt=1456704000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1456704000&endAt=1459296000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1459296000&endAt=1461888000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1461888000&endAt=1464480000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1464480000&endAt=1467072000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1467072000&endAt=1469664000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1469664000&endAt=1472256000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1472256000&endAt=1474848000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1474848000&endAt=1477440000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1477440000&endAt=1480032000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1480032000&endAt=1482624000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1482624000&endAt=1485216000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1485216000&endAt=1487808000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1487808000&endAt=1490400000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1490400000&endAt=1492992000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1492992000&endAt=1495584000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1495584000&endAt=1498176000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1498176000&endAt=1500768000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1500768000&endAt=1503360000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1503360000&endAt=1505952000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1505952000&endAt=1508544000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1508544000&endAt=1511136000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1511136000&endAt=1513728000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1513728000&endAt=1516320000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1516320000&endAt=1518912000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1518912000&endAt=1521504000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1521504000&endAt=1524096000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1524096000&endAt=1526688000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1526688000&endAt=1529280000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1529280000&endAt=1531872000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1531872000&endAt=1534464000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1534464000&endAt=1537056000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1537056000&endAt=1539648000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1539648000&endAt=1542240000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1542240000&endAt=1544832000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1544832000&endAt=1547424000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1547424000&endAt=1550016000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1550016000&endAt=1552608000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1552608000&endAt=1555200000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1555200000&endAt=1557792000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1557792000&endAt=1560384000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1560384000&endAt=1562976000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1562976000&endAt=1565568000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1565568000&endAt=1568160000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1568160000&endAt=1570752000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1570752000&endAt=1573344000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1573344000&endAt=1575936000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1575936000&endAt=1578528000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1578528000&endAt=1581120000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1581120000&endAt=1583712000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1583712000&endAt=1586304000&limit=100', 'https://news.cnyes.com/api/v3/news/category/headline?startAt=1586304000&endAt=1588509731&limit=100']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "t = [2020, 4, 14, 21, 35, 43, 1, 105, 0]\n",
    "\n",
    "# datetime.datetime.now().timestamp()\n",
    "# datetime.datetime.fromtimestamp(1588500008)\n",
    "\n",
    "# d = datetime.timedelta(days=30)\n",
    "# until - d\n",
    "\n",
    "# json.dumps(datetime.datetime(*t[:7]))\n",
    "\n",
    "def startpoints(start: datetime.datetime, until: datetime.datetime):\n",
    "    urls = []\n",
    "    while start < until:\n",
    "        _until = start + datetime.timedelta(days=30)\n",
    "        if _until > until:\n",
    "            _until = until\n",
    "        urls.append('https://news.cnyes.com/api/v3/news/category/headline' +\n",
    "                    f'?startAt={int(start.timestamp())}' +\n",
    "                    f'&endAt={int(_until.timestamp())}' +\n",
    "                    '&limit=100')\n",
    "        start = _until\n",
    "    return urls\n",
    "\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "until = datetime.datetime.now()\n",
    "print(until.timestamp())\n",
    "print(startpoints(start, until))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-12 13:20:00\n",
      "sleep for 5955 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import mktime\n",
    "import datetime\n",
    " \n",
    "fetched_at = datetime.datetime(2020, 4, 12, 10, 0, 0)\n",
    "freq = datetime.timedelta(seconds=12000)\n",
    "print(fetched_at + freq)\n",
    "secs_to_sleep = (fetched_at + freq - datetime.datetime.now()).total_seconds()\n",
    "\n",
    "if secs_to_sleep > 0:\n",
    "    print(\"sleep for {} seconds\".format(int(secs_to_sleep)))\n",
    "else:\n",
    "    print(\"scrape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twint, elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Indexing to Elasticsearch @ http://es:9200\n",
      "...................."
     ]
    }
   ],
   "source": [
    "import twint\n",
    "\n",
    "c = twint.Config()\n",
    "\n",
    "# c.Username = \"YahooFinance\"\n",
    "# c.Username = \"CNBC\"\n",
    "c.Search = '$AAPL'\n",
    "c.Limit = 10\n",
    "# c.Since= '2017-12-27'\n",
    "# c.Until = '2017-12-31'\n",
    "# c.Store_csv = True\n",
    "# c.Output = \"none\"\n",
    "c.Elasticsearch = \"http://es:9200\"\n",
    "c.Debug = True\n",
    "\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# html = etree.tostring(article.clean_top_node, encoding='utf-8').decode('utf-8')\n",
    "# e = etree.fromstring(html)\n",
    "# etree.tostring(e)\n",
    "# print(etree.tostring(article.top_node)[:300])\n",
    "# print(etree.tostring(article.clean_top_node)[:300])\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(\"elasticsearch\")\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch_dsl import Q\n",
    "from app.store import es\n",
    "\n",
    "es.init()\n",
    "# client = elasticsearch.Elasticsearch(['es:9200'])\n",
    "# client.indices.delete(index=\"news_rss\")\n",
    "# client.indices.delete(index=\"news_page\")\n",
    "\n",
    "def f():\n",
    "    s = es.Page.search()\n",
    "#     s = s.filter('wildcard', from_url=\"*cnyes*\").filter('term', http_status=\"*cnyes*\")\n",
    "    q = Q('wildcard', from_url=\"*cnyes.com*\") \\\n",
    "            & ~Q(\"term\", http_status=200)\n",
    "    print(q)\n",
    "    s = s.filter(q)\n",
    "    \n",
    "    results = s.execute()\n",
    "    for page in results:\n",
    "        print(page.from_url, page.http_status)\n",
    "    # s.scan()\n",
    "#     for p in s.scan():\n",
    "#         yield p.from_url\n",
    "\n",
    "# for x in f():\n",
    "#     print(x)\n",
    "#     break\n",
    "# f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {}, '_d_': {'from_url': 'aaa.com'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.store import es\n",
    "\n",
    "p = es.Page(from_url=\"aaa.com\")\n",
    "p.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rss(index='news_rss', id='https://some.url.com/?query=like&thisad')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "from lxml import etree\n",
    "import elasticsearch\n",
    "from elasticsearch_dsl import connections, Document, Date, Keyword, Q, Search, Text, Range, Integer\n",
    "\n",
    "class Rss(Document):\n",
    "    url = Keyword(required=True)\n",
    "    ticker = Keyword()\n",
    "    freq = Integer()  # seconds (default: 2 days)\n",
    "    n_retries = Integer()\n",
    "    fetched_at = Date()\n",
    "\n",
    "    class Index:\n",
    "        name = \"news_rss\"\n",
    "        settings = {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 0\n",
    "        }\n",
    "\n",
    "    def save(self, **kwargs):\n",
    "        self.meta.id = self.url\n",
    "        self.n_retries = self.n_retries or 0\n",
    "        self.freq = self.freq or 2*24*60*60\n",
    "        # self.created_at = datetime.datetime.now()\n",
    "        return super().save(**kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_or_create(cls, url) -> Rss:\n",
    "        try:\n",
    "            rss = cls.get(id=url)\n",
    "        except elasticsearch.NotFoundError:\n",
    "            rss = cls(url=url)\n",
    "            rss.save()\n",
    "        return rss\n",
    "\n",
    "connections.create_connection(hosts=['es:9200'])\n",
    "Rss.init()\n",
    "\n",
    "# rss = Rss(url=\"https://some.url.com/?query=like&this\")\n",
    "# rss.save()\n",
    "\n",
    "r = Rss.get_or_create(\"https://some.url.com/?query=like&thisad\")\n",
    "# print(r.n_retries)\n",
    "print(r)\n",
    "\n",
    "\n",
    "# for i, hit in enumerate(scan_twint('ReutersBiz')):\n",
    "#     print(hit.urls)\n",
    "#     if i > 10:\n",
    "#         break\n",
    "\n",
    "# connections.create_connection(hosts=['es:9200'])\n",
    "# connections.create_connection(hosts=['es:9200'])\n",
    "# Page.init()\n",
    "# s = Page.search()\n",
    "# s.query = Q({\"match\": {\"src_url\": \"aaa.com\"}})\n",
    "# resp = s.execute()\n",
    "# print(resp.hits.total.value)\n",
    "# Page.is_existed('aaav.com')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch_dsl import connections, Document, Date, Keyword, Q, Search, Text, Range, Integer\n",
    "\n",
    "q = Q({\n",
    "        \"range\": {\n",
    "            \"date\": {\n",
    "                \"gte\": \"2000-01-01 00:00:00\",\n",
    "                \"lt\": \"2025-01-01 00:00:00\",\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "client = elasticsearch.Elasticsearch(['es:9200'])\n",
    "s = Search(using=client, index=\"twinttweets\").query(q).filter(\"terms\", username=[\"CNBC\"])\n",
    "\n",
    "# for hit in s.scan():\n",
    "#     print(hit)\n",
    "hit = next(s.scan())\n",
    "hit.username\n",
    "hasattr(hit, \"urls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReutersBiz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(hit.username)\n",
    "hit.username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @dataclass, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedTicker(p_text='some p text', tickers=[{'a_text': 'some a text', 'ticker': 'AAA'}])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import dataclasses \n",
    "from typing import Tuple, List\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class _TickerAnchor:\n",
    "    a_text: str\n",
    "    ticker: str\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ParsedTicker:\n",
    "    p_text: str  # <p>...text...</p>\n",
    "    tickers: List[_TickerAnchor]\n",
    "    \n",
    "\n",
    "t = ParsedTicker('some p text', [_TickerAnchor('some a text', 'AAA')])\n",
    "s = json.dumps(dataclasses.asdict(t))\n",
    "ParsedTicker(**json.loads(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "ParsedTicker = namedtuple('ParsedTicker', ['p_text', 'symbols'])\n",
    "Symbol = namedtuple('Symbol', ['a_text', 'symbol'])\n",
    "\n",
    "Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/twint/app\n",
      "Page(index='news_page', id='aaa.com')\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/twint/app\n",
    "from app.store import es\n",
    "\n",
    "es.init()\n",
    "p = es.Page(from_url=\"aaa.com\")\n",
    "p.save()\n",
    "# p.meta.id = 'aaa'\n",
    "print(p)\n",
    "# p.meta.id = 'bbb'\n",
    "# p.meta.id\n",
    "# p.save()\n",
    "# type(p.meta)\n",
    "# p.meta.id = 'aaa.com'\n",
    "# p.save()\n",
    "# p.created_at is None\n",
    "\n",
    "# p = es.Page.get(id=\"aaa.com\")\n",
    "# p.meta.id='aaa'\n",
    "# p.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = set(a)\n",
    "b.add(4)\n",
    "b\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
